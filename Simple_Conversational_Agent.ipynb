{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Building a Conversational Agent with Context Awareness**"
      ],
      "metadata": {
        "id": "lP1AFpEibkq6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple chatbots lack the ability to maintain context, leading to disjointed and frustrating user experiences. Thus implemented a conversational agent that can remember and refer to previous parts of the conversation, enhancing the overall interaction quality.\n",
        "\n",
        "**Key Components**\n",
        "*   **Language Model**: The core AI component that generates responses.\n",
        "*   **Prompt Template**: Defines the structure of our conversations.\n",
        "*   **History Manager**: Manages conversation history and context.\n",
        "*   **Message Store**: Stores the messages for each conversation session.\n",
        "\n"
      ],
      "metadata": {
        "id": "RhtRpzLkdYzR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A conversational agent offers several advantages:**\n",
        "*   **Context Awareness**: The agent can refer to previous parts of the    conversation, leading to more natural interactions.\n",
        "*   **Simplicity**: The modular design keeps the implementation straightforward.\n",
        "*   **Flexibility**: It's easy to modify the conversation structure or switch to a different language model.\n",
        "*  **Scalability**: The session-based approach allows for managing multiple independent conversations."
      ],
      "metadata": {
        "id": "DZK6fgZffx8t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IWvWvC7bbYim",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "823491cf-fe07-4c69-f0be-d8ec72d25011"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/209.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.6/209.6 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/84.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.3/84.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        " %pip install -q langchain langchain_experimental openai python-dotenv langchain_openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "from langchain_community.chat_message_histories import ChatMessageHistory\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "import os\n",
        "from dotenv import load_dotenv"
      ],
      "metadata": {
        "id": "dBHpTwgncryj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass, os\n",
        "\n",
        "# Ask user for API key (hidden input)\n",
        "api_key = getpass.getpass(\"Enter your OPENAI API key: \")\n",
        "\n",
        "# Save to .env\n",
        "with open(\".env\", \"w\") as f:\n",
        "    f.write(f\"OPENAI_API_KEY={api_key}\\n\")\n",
        "\n",
        "# Install dotenv\n",
        "!pip install python-dotenv > /dev/null\n",
        "\n",
        "# Load .env\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "print(\"API Key loaded successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3VFK-kCkDTD",
        "outputId": "68b35fed-4547-4764-d7cb-613d4bcc4d77"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your OPENAI API key: ··········\n",
            "API Key loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", max_tokens=1000, temperature=0)"
      ],
      "metadata": {
        "id": "_FvZUL7pl2Rc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful AI assistant that always give reliable and responsive response\"),\n",
        "    MessagesPlaceholder(variable_name=\"history\"),\n",
        "    (\"human\", \"{input}\")\n",
        "])"
      ],
      "metadata": {
        "id": "fdn0d1dsuUE4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store = {}\n",
        "\n",
        "def get_chat_history(session_id: str):\n",
        "    if session_id not in store:\n",
        "        store[session_id] = ChatMessageHistory()\n",
        "    return store[session_id]\n",
        "\n",
        "runnable = RunnableWithMessageHistory(\n",
        "    runnable=prompt | llm,\n",
        "    get_session_history=get_chat_history,\n",
        "    input_messages_key=\"input\",\n",
        "    history_messages_key=\"history\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "qjDPame-tfQP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt | llm"
      ],
      "metadata": {
        "id": "lhhz2KjjtkuZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain_with_history = RunnableWithMessageHistory(\n",
        "    chain,\n",
        "    get_chat_history,\n",
        "    input_messages_key=\"input\",\n",
        "    history_messages_key=\"history\"\n",
        ")"
      ],
      "metadata": {
        "id": "C6RUsQv0vcVC"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "session_id = \"user_89\"\n",
        "\n",
        "\n",
        "response1 = chain_with_history.invoke(\n",
        "    {\"input\": \"Hi! How are you?\"},\n",
        "    config={\"configurable\": {\"session_id\": session_id}}\n",
        ")\n",
        "print(\"AI:\", response1.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1w0FknVTvmZ5",
        "outputId": "f68dad01-e3e9-4f1e-9d1b-ca4b0a99813d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI: Hello! I'm just a program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response2 = chain_with_history.invoke(\n",
        "    {\"input\": \"My name is ram and who created you?\"},\n",
        "    config={\"configurable\": {\"session_id\": session_id}}\n",
        ")\n",
        "print(\"AI:\", response2.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s11633mFzRFn",
        "outputId": "947f3109-db2a-4293-b4ed-031961cd0542"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI: Hello, Ram! I was created by OpenAI, an organization focused on developing and advancing artificial intelligence. How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nConversation History:\")\n",
        "for message in store[session_id].messages:\n",
        "    print(f\"{message.type}: {message.content}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dmt_3aGNvvM9",
        "outputId": "8d826826-2934-4ed1-a2d7-1b1867aa686c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Conversation History:\n",
            "human: Hi! How are you?\n",
            "ai: Hello! I'm just a program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\n",
            "human: My name is ram and who created you?\n",
            "ai: Hello, Ram! I was created by OpenAI, an organization focused on developing and advancing artificial intelligence. How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response3 = chain_with_history.invoke(\n",
        "    {\"input\": \"What is my name ?\"},\n",
        "    config={\"configurable\": {\"session_id\": session_id}}\n",
        ")\n",
        "print(\"AI:\", response2.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBIgfEdVzryo",
        "outputId": "174cd03f-ed13-4637-978d-04bee86338eb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI: Your name is Ram. How can I assist you further, Ram?\n"
          ]
        }
      ]
    }
  ]
}