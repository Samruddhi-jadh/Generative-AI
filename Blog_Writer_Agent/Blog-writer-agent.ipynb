{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14003851,"sourceType":"datasetVersion","datasetId":8922560}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip -qq install -U langchain langchain-community langgraph pydantic google-ai-generativelanguage==0.6.15 langchain-google-genai","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-05T05:00:15.831973Z","iopub.execute_input":"2025-12-05T05:00:15.832428Z","iopub.status.idle":"2025-12-05T05:03:38.902480Z","shell.execute_reply.started":"2025-12-05T05:00:15.832401Z","shell.execute_reply":"2025-12-05T05:03:38.900986Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!pip install \"pydantic>=2.8,<3.0\"\n!pip install \"langchain-core>=0.3.10\"\n!pip install \"langgraph>=1.0.0\"\n!pip install \"langchain-google-genai>=2.0.0\"\n!pip install \"google-genai>=1.50.0\"\n!pip install reflex\n!pip install pyttsx3 gTTS soundfile pydub SpeechRecognition","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T05:03:38.904748Z","iopub.execute_input":"2025-12-05T05:03:38.905206Z","iopub.status.idle":"2025-12-05T05:04:09.726349Z","shell.execute_reply.started":"2025-12-05T05:03:38.905164Z","shell.execute_reply":"2025-12-05T05:04:09.725149Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pydantic<3.0,>=2.8 in /usr/local/lib/python3.11/dist-packages (2.12.5)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0,>=2.8) (0.7.0)\nRequirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0,>=2.8) (2.41.5)\nRequirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0,>=2.8) (4.15.0)\nRequirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0,>=2.8) (0.4.2)\nRequirement already satisfied: langchain-core>=0.3.10 in /usr/local/lib/python3.11/dist-packages (0.3.80)\nRequirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.3.10) (0.4.8)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.3.10) (9.1.2)\nRequirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.3.10) (1.33)\nRequirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.3.10) (6.0.3)\nRequirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.3.10) (4.15.0)\nRequirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.3.10) (25.0)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.3.10) (2.12.5)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.3.10) (3.0.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.10) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.10) (3.11.0)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.10) (2.32.5)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.10) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.10) (0.23.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core>=0.3.10) (0.7.0)\nRequirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core>=0.3.10) (2.41.5)\nRequirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core>=0.3.10) (0.4.2)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.10) (4.11.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.10) (2025.10.5)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.10) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.10) (3.11)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.10) (0.16.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.10) (3.4.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.10) (2.5.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.10) (1.3.1)\nRequirement already satisfied: langgraph>=1.0.0 in /usr/local/lib/python3.11/dist-packages (1.0.1)\nRequirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph>=1.0.0) (0.3.80)\nRequirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from langgraph>=1.0.0) (3.0.1)\nRequirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langgraph>=1.0.0) (1.0.1)\nRequirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from langgraph>=1.0.0) (0.2.12)\nRequirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langgraph>=1.0.0) (2.12.5)\nRequirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph>=1.0.0) (3.6.0)\nRequirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph>=1.0.0) (0.4.8)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph>=1.0.0) (9.1.2)\nRequirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph>=1.0.0) (1.33)\nRequirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph>=1.0.0) (6.0.3)\nRequirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph>=1.0.0) (4.15.0)\nRequirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph>=1.0.0) (25.0)\nRequirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph>=1.0.0) (1.12.0)\nRequirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph>=1.0.0) (0.28.1)\nRequirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph>=1.0.0) (3.11.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph>=1.0.0) (0.7.0)\nRequirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph>=1.0.0) (2.41.5)\nRequirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph>=1.0.0) (0.4.2)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph>=1.0.0) (4.11.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph>=1.0.0) (2025.10.5)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph>=1.0.0) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph>=1.0.0) (3.11)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph>=1.0.0) (0.16.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.1->langgraph>=1.0.0) (3.0.0)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph>=1.0.0) (2.32.5)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph>=1.0.0) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph>=1.0.0) (0.23.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph>=1.0.0) (3.4.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph>=1.0.0) (2.5.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph>=1.0.0) (1.3.1)\nRequirement already satisfied: langchain-google-genai>=2.0.0 in /usr/local/lib/python3.11/dist-packages (2.0.10)\nRequirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai>=2.0.0) (1.2.0)\nRequirement already satisfied: google-generativeai<0.9.0,>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai>=2.0.0) (0.8.5)\nRequirement already satisfied: langchain-core<0.4.0,>=0.3.37 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai>=2.0.0) (0.3.80)\nRequirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai>=2.0.0) (2.12.5)\nRequirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai>=2.0.0) (0.6.15)\nRequirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai>=2.0.0) (2.28.1)\nRequirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai>=2.0.0) (2.177.0)\nRequirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai>=2.0.0) (2.38.0)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai>=2.0.0) (5.29.5)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai>=2.0.0) (4.67.1)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai>=2.0.0) (4.15.0)\nRequirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai>=2.0.0) (1.26.1)\nRequirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.37->langchain-google-genai>=2.0.0) (0.4.8)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.37->langchain-google-genai>=2.0.0) (9.1.2)\nRequirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.37->langchain-google-genai>=2.0.0) (1.33)\nRequirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.37->langchain-google-genai>=2.0.0) (6.0.3)\nRequirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.37->langchain-google-genai>=2.0.0) (25.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai>=2.0.0) (0.7.0)\nRequirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai>=2.0.0) (2.41.5)\nRequirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai>=2.0.0) (0.4.2)\nRequirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai>=2.0.0) (1.70.0)\nRequirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai>=2.0.0) (2.32.5)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai>=2.0.0) (5.5.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai>=2.0.0) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai>=2.0.0) (4.9.1)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<0.4.0,>=0.3.37->langchain-google-genai>=2.0.0) (3.0.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<0.4.0,>=0.3.37->langchain-google-genai>=2.0.0) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<0.4.0,>=0.3.37->langchain-google-genai>=2.0.0) (3.11.0)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<0.4.0,>=0.3.37->langchain-google-genai>=2.0.0) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<0.4.0,>=0.3.37->langchain-google-genai>=2.0.0) (0.23.0)\nRequirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai>=2.0.0) (0.22.0)\nRequirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai>=2.0.0) (0.2.0)\nRequirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai>=2.0.0) (4.2.0)\nRequirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai>=2.0.0) (1.74.0)\nRequirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai>=2.0.0) (1.71.2)\nRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai>=2.0.0) (3.0.9)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<0.4.0,>=0.3.37->langchain-google-genai>=2.0.0) (4.11.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<0.4.0,>=0.3.37->langchain-google-genai>=2.0.0) (2025.10.5)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<0.4.0,>=0.3.37->langchain-google-genai>=2.0.0) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<0.4.0,>=0.3.37->langchain-google-genai>=2.0.0) (3.11)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<0.4.0,>=0.3.37->langchain-google-genai>=2.0.0) (0.16.0)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai>=2.0.0) (0.6.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai>=2.0.0) (3.4.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai>=2.0.0) (2.5.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<0.4.0,>=0.3.37->langchain-google-genai>=2.0.0) (1.3.1)\nRequirement already satisfied: google-genai>=1.50.0 in /usr/local/lib/python3.11/dist-packages (1.53.0)\nRequirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from google-genai>=1.50.0) (4.11.0)\nRequirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-auth[requests]<3.0.0,>=2.14.1->google-genai>=1.50.0) (2.38.0)\nRequirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from google-genai>=1.50.0) (0.28.1)\nRequirement already satisfied: pydantic<3.0.0,>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from google-genai>=1.50.0) (2.12.5)\nRequirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.11/dist-packages (from google-genai>=1.50.0) (2.32.5)\nRequirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from google-genai>=1.50.0) (9.1.2)\nRequirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from google-genai>=1.50.0) (15.0.1)\nRequirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /usr/local/lib/python3.11/dist-packages (from google-genai>=1.50.0) (4.15.0)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai>=1.50.0) (3.11)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai>=1.50.0) (1.3.1)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai>=1.50.0) (5.5.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai>=1.50.0) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai>=1.50.0) (4.9.1)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai>=1.50.0) (2025.10.5)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai>=1.50.0) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai>=1.50.0) (0.16.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai>=1.50.0) (0.7.0)\nRequirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai>=1.50.0) (2.41.5)\nRequirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai>=1.50.0) (0.4.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.28.1->google-genai>=1.50.0) (3.4.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.28.1->google-genai>=1.50.0) (2.5.0)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai>=1.50.0) (0.6.1)\nRequirement already satisfied: reflex in /usr/local/lib/python3.11/dist-packages (0.8.21)\nRequirement already satisfied: alembic<2.0,>=1.15.2 in /usr/local/lib/python3.11/dist-packages (from reflex) (1.17.1)\nCollecting click>=8.2 (from reflex)\n  Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\nRequirement already satisfied: granian>=2.5.5 in /usr/local/lib/python3.11/dist-packages (from granian[reload]>=2.5.5->reflex) (2.6.0)\nRequirement already satisfied: httpx<1.0,>=0.23.3 in /usr/local/lib/python3.11/dist-packages (from reflex) (0.28.1)\nRequirement already satisfied: packaging<26,>=24.2 in /usr/local/lib/python3.11/dist-packages (from reflex) (25.0)\nRequirement already satisfied: platformdirs<5.0,>=4.3.7 in /usr/local/lib/python3.11/dist-packages (from reflex) (4.5.0)\nRequirement already satisfied: pydantic<3.0,>=1.10.21 in /usr/local/lib/python3.11/dist-packages (from reflex) (2.12.5)\nRequirement already satisfied: python-multipart<1.0,>=0.0.20 in /usr/local/lib/python3.11/dist-packages (from reflex) (0.0.20)\nRequirement already satisfied: python-socketio<6.0,>=5.12.0 in /usr/local/lib/python3.11/dist-packages (from reflex) (5.15.0)\nRequirement already satisfied: redis<8.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from reflex) (7.1.0)\nRequirement already satisfied: reflex-hosting-cli>=0.1.59 in /usr/local/lib/python3.11/dist-packages (from reflex) (0.1.59)\nRequirement already satisfied: rich<15,>=13 in /usr/local/lib/python3.11/dist-packages (from reflex) (14.2.0)\nRequirement already satisfied: sqlmodel<0.1,>=0.0.27 in /usr/local/lib/python3.11/dist-packages (from reflex) (0.0.27)\nRequirement already satisfied: starlette>=0.47.0 in /usr/local/lib/python3.11/dist-packages (from reflex) (0.47.2)\nRequirement already satisfied: typing-extensions>=4.13.0 in /usr/local/lib/python3.11/dist-packages (from reflex) (4.15.0)\nRequirement already satisfied: wrapt<3.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from reflex) (1.17.2)\nRequirement already satisfied: SQLAlchemy>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from alembic<2.0,>=1.15.2->reflex) (2.0.41)\nRequirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic<2.0,>=1.15.2->reflex) (1.3.10)\nRequirement already satisfied: watchfiles~=1.0 in /usr/local/lib/python3.11/dist-packages (from granian[reload]>=2.5.5->reflex) (1.1.1)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1.0,>=0.23.3->reflex) (4.11.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0,>=0.23.3->reflex) (2025.10.5)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0,>=0.23.3->reflex) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1.0,>=0.23.3->reflex) (3.11)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0,>=0.23.3->reflex) (0.16.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0,>=1.10.21->reflex) (0.7.0)\nRequirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0,>=1.10.21->reflex) (2.41.5)\nRequirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0,>=1.10.21->reflex) (0.4.2)\nRequirement already satisfied: bidict>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from python-socketio<6.0,>=5.12.0->reflex) (0.23.1)\nRequirement already satisfied: python-engineio>=4.11.0 in /usr/local/lib/python3.11/dist-packages (from python-socketio<6.0,>=5.12.0->reflex) (4.12.3)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<15,>=13->reflex) (4.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<15,>=13->reflex) (2.19.2)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1.0,>=0.23.3->reflex) (1.3.1)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<15,>=13->reflex) (0.1.2)\nRequirement already satisfied: simple-websocket>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from python-engineio>=4.11.0->python-socketio<6.0,>=5.12.0->reflex) (1.1.0)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy>=1.4.0->alembic<2.0,>=1.15.2->reflex) (3.2.3)\nRequirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic<2.0,>=1.15.2->reflex) (3.0.3)\nRequirement already satisfied: wsproto in /usr/local/lib/python3.11/dist-packages (from simple-websocket>=0.10.0->python-engineio>=4.11.0->python-socketio<6.0,>=5.12.0->reflex) (1.3.2)\nDownloading click-8.3.1-py3-none-any.whl (108 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.3/108.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: click\n  Attempting uninstall: click\n    Found existing installation: click 8.1.8\n    Uninstalling click-8.1.8:\n      Successfully uninstalled click-8.1.8\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ngtts 2.5.4 requires click<8.2,>=7.1, but you have click 8.3.1 which is incompatible.\npreprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.9.2 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed click-8.3.1\nRequirement already satisfied: pyttsx3 in /usr/local/lib/python3.11/dist-packages (2.99)\nRequirement already satisfied: gTTS in /usr/local/lib/python3.11/dist-packages (2.5.4)\nRequirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\nRequirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (0.25.1)\nRequirement already satisfied: SpeechRecognition in /usr/local/lib/python3.11/dist-packages (3.14.4)\nRequirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from gTTS) (2.32.5)\nCollecting click<8.2,>=7.1 (from gTTS)\n  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\nRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (2.0.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.26.4)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from SpeechRecognition) (4.15.0)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.23)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gTTS) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gTTS) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gTTS) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gTTS) (2025.10.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->soundfile) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->soundfile) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->soundfile) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->soundfile) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->soundfile) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->soundfile) (2.4.1)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->soundfile) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->soundfile) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->soundfile) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->soundfile) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->soundfile) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->soundfile) (2024.2.0)\nUsing cached click-8.1.8-py3-none-any.whl (98 kB)\nInstalling collected packages: click\n  Attempting uninstall: click\n    Found existing installation: click 8.3.1\n    Uninstalling click-8.3.1:\n      Successfully uninstalled click-8.3.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\nreflex-hosting-cli 0.1.59 requires click>=8.2, but you have click 8.1.8 which is incompatible.\nreflex 0.8.21 requires click>=8.2, but you have click 8.1.8 which is incompatible.\npreprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.9.2 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed click-8.1.8\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nimport operator\nfrom typing import Annotated, Literal\nfrom typing_extensions import TypedDict\nfrom pydantic import BaseModel\n\nfrom langgraph.graph import StateGraph, MessagesState, START, END\nfrom langgraph.prebuilt import ToolNode\nfrom langgraph.graph.message import add_messages\nfrom langgraph.types import Command\n\nfrom langchain_google_genai import ChatGoogleGenerativeAI\nfrom langchain.chat_models import init_chat_model\nfrom langchain_core.messages import AnyMessage, HumanMessage\n\nfrom google.colab import userdata\n\nfrom getpass import getpass\nimport os\n\n# Enter the key securely (won't be visible when typed)\nos.environ['API_KEY'] = getpass('Enter your API key: ')\n\n# Use the key\nGOOGLE_API_KEY = os.environ['API_KEY']\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T05:04:09.727865Z","iopub.execute_input":"2025-12-05T05:04:09.728206Z","iopub.status.idle":"2025-12-05T05:04:28.403758Z","shell.execute_reply.started":"2025-12-05T05:04:09.728175Z","shell.execute_reply":"2025-12-05T05:04:28.402681Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":"Enter your API key:  ········\n"}],"execution_count":3},{"cell_type":"code","source":"# Define LLM client\nllm = ChatGoogleGenerativeAI(\n    model=\"gemini-2.0-flash\",\n    api_key=GOOGLE_API_KEY,\n    system_instruction=\"\"\"You are an expert technical writer. Always give clear,\n     concise, and straight-to-the-point answers.\"\"\"\n)\n\n# Define the graph state\nclass State(dict):\n    text: str\n    topics: str\n    title :str\n    best_title: str\n    blog_markdown: str\n\n# Define nodes (steps)\ndef extract_topics(state: State) -> State:\n    prompt = f\"Extract 1-3 key topics from the following text:\\n\\n{state['text']}\"\n    resp = llm.invoke(prompt)\n    state[\"topics\"] = resp.content.strip()\n    return state\n\ndef generate_title(state: State) -> State:\n    prompt = f\"Generate two catchy blog titles for each one these topics:\\n\\n{state['topics']}\"\n    resp = llm.invoke(prompt)\n    state[\"title\"] = resp.content.strip()\n    return state\n\n# --- New nodes to add (keep style & formatting of original code) ---\ndef choose_title(state: State) -> State:\n    \"\"\"\n    Choose the best title from `state['title']` (which contains generated title options).\n    Strategy: ask LLM to rank and return the single best title.\n    \"\"\"\n    prompt = (\n        \"From the following candidate titles (pick exactly one best title). \"\n        \"Return only the chosen title on a single line.\\n\\n\"\n        f\"{state['title']}\"\n    )\n    resp = llm.invoke(prompt)\n    # ensure single-line title\n    best = resp.content.strip().splitlines()[0].strip()\n    state[\"best_title\"] = best\n    return state\n\ndef write_blog(state: State) -> State:\n    \"\"\"\n    Generate the blog body using the chosen title `state['best_title']` and the original input text.\n    Produce markdown output suitable for platform-specific templates (we'll post-format later).\n    \"\"\"\n    prompt = (\n        f\"Write a concise but thorough blog post in markdown using the title below. \"\n        f\"Use ~6–10 short paragraphs, include 2-3 subheadings, and a short 2-line conclusion.\\n\\n\"\n        f\"Title: {state['best_title']}\\n\\n\"\n        f\"Source/context text:\\n{state['text']}\\n\\n\"\n        \"Return the blog in markdown only (no commentary).\"\n    )\n    resp = llm.invoke(prompt)\n    state[\"blog_markdown\"] = resp.content.strip()\n    return state\n\n# Build the graph\nworkflow = StateGraph(State)\nworkflow.add_node(\"extract_topics\", extract_topics)\nworkflow.add_node(\"generate_title\", generate_title)\nworkflow.add_node(\"choose_title\", choose_title)\nworkflow.add_node(\"write_blog\", write_blog)\n\n# Flow: extract_topics → generate_title → END\nworkflow.set_entry_point(\"extract_topics\")\nworkflow.add_edge(\"extract_topics\", \"generate_title\")\nworkflow.add_edge(\"generate_title\", \"choose_title\")\nworkflow.add_edge(\"choose_title\", \"write_blog\")\nworkflow.add_edge(\"write_blog\", END)\n\n\n# Compile runnable graph\ngraph = workflow.compile()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T05:04:28.406185Z","iopub.execute_input":"2025-12-05T05:04:28.406768Z","iopub.status.idle":"2025-12-05T05:04:28.449614Z","shell.execute_reply.started":"2025-12-05T05:04:28.406731Z","shell.execute_reply":"2025-12-05T05:04:28.448530Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"PLATFORM_TEMPLATES = {\n    \"linkedin\": {\n        \"excerpt_chars\": 400,\n        \"add_cta\": True,\n        \"include_hashtags\": True,\n        \"hashtags\": [\"#AI\", \"#RAG\", \"#LlamaIndex\"]\n    },\n    \"substack\": {\n        \"excerpt_chars\": 800,\n        \"add_cta\": False,\n        \"include_hashtags\": False\n    },\n    \"medium\": {\n        \"excerpt_chars\": 500,\n        \"add_cta\": True,\n        \"include_hashtags\": False\n    },\n    \"instagram\": {\n        \"excerpt_chars\": 2200,  # caption limit ~2200 chars\n        \"add_cta\": True,\n        \"include_hashtags\": True,\n        \"visual_hint\": True\n    }\n}\n\ndef render_for_platform(markdown_text: str, platform: str):\n    \"\"\"\n    Convert base markdown blog into platform-specific formats.\n    Output: dict with {'content': rendered_text}\n    \"\"\"\n    platform = platform.lower()\n\n    if platform == \"linkedin\":\n        # LinkedIn supports minimal markdown → convert to rich-text-ish formatting\n        rendered = markdown_text.replace(\"##\", \"###\").replace(\"###\", \"####\")\n        rendered = rendered.replace(\"**\", \"\")  # LinkedIn strips bold markers\n        return {\"content\": rendered}\n\n    elif platform == \"medium\":\n        # Medium accepts full markdown\n        return {\"content\": markdown_text}\n\n    elif platform == \"substack\":\n        # Substack supports HTML-rich markdown\n        rendered = markdown_text + \"\\n\\n---\\n*Written via AI Blog Generator*\"\n        return {\"content\": rendered}\n\n    elif platform == \"instagram\":\n        # Instagram ≠ markdown → break blog into punchy carousel captions\n        lines = markdown_text.split(\"\\n\")\n        captions = [l[:1900] for l in lines if l.strip()]\n        return {\"content\": \"\\n\\n\".join(captions)}\n\n    else:\n        return {\"content\": markdown_text}\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T05:04:28.450760Z","iopub.execute_input":"2025-12-05T05:04:28.451101Z","iopub.status.idle":"2025-12-05T05:04:28.463771Z","shell.execute_reply.started":"2025-12-05T05:04:28.451074Z","shell.execute_reply":"2025-12-05T05:04:28.462271Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"graph","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T05:04:28.464971Z","iopub.execute_input":"2025-12-05T05:04:28.465824Z","iopub.status.idle":"2025-12-05T05:04:28.636814Z","shell.execute_reply.started":"2025-12-05T05:04:28.465793Z","shell.execute_reply":"2025-12-05T05:04:28.635664Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"<langgraph.graph.state.CompiledStateGraph object at 0x7eb27f35da50>","image/png":"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"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"input_text = (\n    \"LlamaIndex agents are AI-powered reasoning and decision engines designed to automate complex tasks, \"\n    \"especially those involving private or domain-specific data. \"\n    \"LlamaIndex is highly regarded for its data-centric approach and strong Retrieval-Augmented Generation (RAG) features \"\n    \"when compared to frameworks like LangChain or CrewAI.\"\n)\n\nresult = graph.invoke({\"text\": input_text})\n\nprint(\"Topics:\", result[\"topics\"])\nprint(\"\\n\"+\"=\"*50+\"\\n\")\n\nprint(\"Titles:\", result[\"title\"])\nprint(\"\\n\"+\"=\"*50+\"\\n\")\n\nprint(\"Best Title:\", result[\"best_title\"])\nprint(\"\\n\"+\"=\"*50+\"\\n\")\n\nprint(result[\"blog_markdown\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T05:04:28.637731Z","iopub.execute_input":"2025-12-05T05:04:28.638028Z","iopub.status.idle":"2025-12-05T05:04:36.462447Z","shell.execute_reply.started":"2025-12-05T05:04:28.638006Z","shell.execute_reply":"2025-12-05T05:04:36.461388Z"}},"outputs":[{"name":"stdout","text":"Topics: Here are 3 key topics extracted from the text:\n\n1.  **LlamaIndex Agents:** Focuses on the core subject of the text - the agents themselves and their purpose (reasoning and decision-making).\n2.  **Automation of Complex Tasks:** Highlights the primary function and benefit of using LlamaIndex agents.\n3.  **Data-Centric RAG:** Emphasizes LlamaIndex's strengths, particularly its focus on data and its strong Retrieval-Augmented Generation capabilities.\n\n==================================================\n\nTitles: Okay, here are two catchy blog titles for each of the provided topics:\n\n**1. LlamaIndex Agents:**\n\n*   **Title 1: Unleash Your Data's Potential: Meet the LlamaIndex Agents** (Focuses on the benefit and introduces the agents)\n*   **Title 2: Beyond Chatbots: How LlamaIndex Agents are Revolutionizing AI Decision-Making** (Implies advanced capabilities and innovation)\n\n**2. Automation of Complex Tasks:**\n\n*   **Title 1: From Mundane to Magnificent: Automating Complex Tasks with LlamaIndex** (Highlights the transformation and the tool)\n*   **Title 2: Stop Doing, Start Leading: LlamaIndex and the Future of Task Automation** (Appeals to a leadership perspective and promises time savings)\n\n**3. Data-Centric RAG:**\n\n*   **Title 1: Data is King: Mastering RAG with LlamaIndex's Data-First Approach** (Emphasizes data importance and LlamaIndex's strength)\n*   **Title 2: Supercharge Your RAG: The LlamaIndex Guide to Data-Powered Generation** (Focuses on performance improvement and provides a helpful guide angle)\n\n==================================================\n\nBest Title: Supercharge Your RAG: The LlamaIndex Guide to Data-Powered Generation\n\n==================================================\n\n```markdown\n# Supercharge Your RAG: The LlamaIndex Guide to Data-Powered Generation\n\nIn the ever-evolving landscape of AI, Retrieval-Augmented Generation (RAG) is emerging as a powerful paradigm for building intelligent applications. RAG combines the strengths of pre-trained language models with the ability to retrieve and incorporate information from external knowledge sources, leading to more accurate, relevant, and context-aware responses.\n\nLlamaIndex stands out as a leading framework for building RAG applications, especially when dealing with private or domain-specific data. It provides a comprehensive set of tools and abstractions that simplify the process of indexing, querying, and integrating your data with large language models (LLMs). Unlike some other frameworks, LlamaIndex prioritizes a data-centric approach, making it easier to manage and leverage your unique datasets.\n\n## Why Choose LlamaIndex for RAG?\n\nLlamaIndex offers several key advantages for building robust RAG systems. Its focus on data connectors allows you to seamlessly ingest data from various sources, including PDFs, websites, databases, and more. The framework provides powerful indexing capabilities, enabling you to structure your data for efficient retrieval. Advanced query engines allow you to ask complex questions and retrieve relevant information based on semantic similarity.\n\nThe LlamaIndex agent functionality is another critical aspect. LlamaIndex agents are AI-powered reasoning and decision engines designed to automate complex tasks. They are specifically designed to handle tasks that involve private or domain-specific data.\n\n## Building a RAG Pipeline with LlamaIndex\n\nBuilding a RAG pipeline with LlamaIndex typically involves the following steps: data loading and indexing, query construction, retrieval, and response generation. LlamaIndex simplifies each of these steps with intuitive APIs and pre-built components. You can customize the pipeline to fit your specific needs by choosing different indexing strategies, retrieval algorithms, and LLMs.\n\nThe framework also provides excellent support for evaluation and monitoring, allowing you to track the performance of your RAG system and identify areas for improvement. This iterative process is crucial for ensuring that your RAG application delivers accurate and reliable results.\n\nLlamaIndex empowers developers to create data-powered generation applications that are both powerful and easy to build. Embrace the data, and unlock the potential of RAG.\n```\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"md = result[\"blog_markdown\"]\nlinkedin_post = render_for_platform(md, \"linkedin\")[\"content\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T05:04:36.463350Z","iopub.execute_input":"2025-12-05T05:04:36.463606Z","iopub.status.idle":"2025-12-05T05:04:36.468187Z","shell.execute_reply.started":"2025-12-05T05:04:36.463586Z","shell.execute_reply":"2025-12-05T05:04:36.467186Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"linkedin_post","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T05:04:36.468936Z","iopub.execute_input":"2025-12-05T05:04:36.469214Z","iopub.status.idle":"2025-12-05T05:04:36.489796Z","shell.execute_reply.started":"2025-12-05T05:04:36.469196Z","shell.execute_reply":"2025-12-05T05:04:36.488777Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"'```markdown\\n# Supercharge Your RAG: The LlamaIndex Guide to Data-Powered Generation\\n\\nIn the ever-evolving landscape of AI, Retrieval-Augmented Generation (RAG) is emerging as a powerful paradigm for building intelligent applications. RAG combines the strengths of pre-trained language models with the ability to retrieve and incorporate information from external knowledge sources, leading to more accurate, relevant, and context-aware responses.\\n\\nLlamaIndex stands out as a leading framework for building RAG applications, especially when dealing with private or domain-specific data. It provides a comprehensive set of tools and abstractions that simplify the process of indexing, querying, and integrating your data with large language models (LLMs). Unlike some other frameworks, LlamaIndex prioritizes a data-centric approach, making it easier to manage and leverage your unique datasets.\\n\\n#### Why Choose LlamaIndex for RAG?\\n\\nLlamaIndex offers several key advantages for building robust RAG systems. Its focus on data connectors allows you to seamlessly ingest data from various sources, including PDFs, websites, databases, and more. The framework provides powerful indexing capabilities, enabling you to structure your data for efficient retrieval. Advanced query engines allow you to ask complex questions and retrieve relevant information based on semantic similarity.\\n\\nThe LlamaIndex agent functionality is another critical aspect. LlamaIndex agents are AI-powered reasoning and decision engines designed to automate complex tasks. They are specifically designed to handle tasks that involve private or domain-specific data.\\n\\n#### Building a RAG Pipeline with LlamaIndex\\n\\nBuilding a RAG pipeline with LlamaIndex typically involves the following steps: data loading and indexing, query construction, retrieval, and response generation. LlamaIndex simplifies each of these steps with intuitive APIs and pre-built components. You can customize the pipeline to fit your specific needs by choosing different indexing strategies, retrieval algorithms, and LLMs.\\n\\nThe framework also provides excellent support for evaluation and monitoring, allowing you to track the performance of your RAG system and identify areas for improvement. This iterative process is crucial for ensuring that your RAG application delivers accurate and reliable results.\\n\\nLlamaIndex empowers developers to create data-powered generation applications that are both powerful and easy to build. Embrace the data, and unlock the potential of RAG.\\n```'"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"pip install PyAudio\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T05:04:36.493295Z","iopub.execute_input":"2025-12-05T05:04:36.493672Z","iopub.status.idle":"2025-12-05T05:04:45.293877Z","shell.execute_reply.started":"2025-12-05T05:04:36.493646Z","shell.execute_reply":"2025-12-05T05:04:45.292664Z"}},"outputs":[{"name":"stdout","text":"Collecting PyAudio\n  Using cached PyAudio-0.2.14.tar.gz (47 kB)\n  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nBuilding wheels for collected packages: PyAudio\n  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n  \n  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for PyAudio \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n  \u001b[31m╰─>\u001b[0m See above for output.\n  \n  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n  Building wheel for PyAudio (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n\u001b[31m  ERROR: Failed building wheel for PyAudio\u001b[0m\u001b[31m\n\u001b[0mFailed to build PyAudio\n\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (PyAudio)\u001b[0m\u001b[31m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import speech_recognition as sr\n\ndef record_voice_input():\n    recognizer = sr.Recognizer()\n    with sr.Microphone() as mic:\n        print(\"🎤 Speak now...\")\n        audio = recognizer.listen(mic)\n\n    try:\n        text = recognizer.recognize_google(audio)\n        print(\"Voice Input:\", text)\n        return text\n    except:\n        print(\"Error: Could not understand audio\")\n        return \"\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T05:09:14.106897Z","iopub.execute_input":"2025-12-05T05:09:14.107301Z","iopub.status.idle":"2025-12-05T05:09:14.115085Z","shell.execute_reply.started":"2025-12-05T05:09:14.107278Z","shell.execute_reply":"2025-12-05T05:09:14.113384Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"!pip install openai-whisper\nimport whisper\n\n# Full path to the audio file\naudio_path = \"/kaggle/input/myvoice/New recording 7.m4a\"\n\n# Load Whisper model\nmodel = whisper.load_model(\"base\")\n\n# Transcribe audio\nresult = model.transcribe(audio_path)\n\n# Print transcription\nprint(\"🎤 Transcription:\", result[\"text\"])\n\nprint(\"🎤 Transcribed:\", input_text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T05:29:49.533253Z","iopub.execute_input":"2025-12-05T05:29:49.533643Z","iopub.status.idle":"2025-12-05T05:30:06.634899Z","shell.execute_reply.started":"2025-12-05T05:29:49.533616Z","shell.execute_reply":"2025-12-05T05:30:06.633464Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: openai-whisper in /usr/local/lib/python3.11/dist-packages (20250625)\nRequirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (10.7.0)\nRequirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.60.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (1.26.4)\nRequirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.9.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.6.0+cu124)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (4.67.1)\nRequirement already satisfied: triton>=2 in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (3.2.0)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper) (0.43.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->openai-whisper) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->openai-whisper) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->openai-whisper) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->openai-whisper) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->openai-whisper) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->openai-whisper) (2.4.1)\nRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2025.11.3)\nRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2.32.5)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.20.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (4.15.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2025.10.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.10.5)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper) (3.0.3)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->openai-whisper) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->openai-whisper) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->openai-whisper) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->openai-whisper) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->openai-whisper) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->openai-whisper) (2024.2.0)\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n","output_type":"stream"},{"name":"stdout","text":"🎤 Transcription:  generate block following cream on topic agent quilting\n🎤 Transcribed: LlamaIndex agents are AI-powered reasoning and decision engines designed to automate complex tasks, especially those involving private or domain-specific data. LlamaIndex is highly regarded for its data-centric approach and strong Retrieval-Augmented Generation (RAG) features when compared to frameworks like LangChain or CrewAI.\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"result = graph.invoke({\"text\": input_text})\n\nprint(\"🔹 Topics:\", result[\"topics\"])\nprint(\"🔹 Titles:\", result[\"title\"])\nprint(\"\\n----- BLOG OUTPUT -----\\n\")\nprint(result[\"blog_markdown\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T05:31:10.894705Z","iopub.execute_input":"2025-12-05T05:31:10.895156Z","iopub.status.idle":"2025-12-05T05:31:18.503644Z","shell.execute_reply.started":"2025-12-05T05:31:10.895124Z","shell.execute_reply":"2025-12-05T05:31:18.502473Z"}},"outputs":[{"name":"stdout","text":"🔹 Topics: Here are 3 key topics extracted from the text:\n\n1.  **LlamaIndex Agents:** Focuses on their purpose as AI reasoning and decision engines.\n2.  **Automation of Complex Tasks:** Highlights the primary function of these agents.\n3.  **Data-Centric RAG Capabilities:** Emphasizes LlamaIndex's strength in handling data retrieval and generation, especially in private or domain-specific contexts.\n🔹 Titles: Okay, here are two catchy blog titles for each of the 3 key topics you provided:\n\n**1. LlamaIndex Agents: Focuses on their purpose as AI reasoning and decision engines.**\n\n*   **Title 1:** LlamaIndex Agents: Your AI Brain for Complex Decisions\n*   **Title 2:** Unleash AI Reasoning: How LlamaIndex Agents Think and Act\n\n**2. Automation of Complex Tasks: Highlights the primary function of these agents.**\n\n*   **Title 1:** Ditch the Drudgery: LlamaIndex Agents Automate Your Toughest Tasks\n*   **Title 2:** AI on Autopilot: Simplifying Complex Workflows with LlamaIndex Agents\n\n**3. Data-Centric RAG Capabilities: Emphasizes LlamaIndex's strength in handling data retrieval and generation, especially in private or domain-specific contexts.**\n\n*   **Title 1:** Supercharge Your Data: LlamaIndex RAG for Private Knowledge\n*   **Title 2:** From Data Silos to Smart Insights: Unlock Your Private Knowledge with LlamaIndex RAG\n\n----- BLOG OUTPUT -----\n\n```markdown\n# Unleash AI Reasoning: How LlamaIndex Agents Think and Act\n\nLlamaIndex agents are revolutionizing how we interact with data, particularly when dealing with private or domain-specific information. These AI-powered agents function as sophisticated reasoning and decision-making engines, automating complex tasks that would traditionally require significant human involvement. They represent a significant leap forward in leveraging AI for data-driven solutions.\n\nAt their core, LlamaIndex agents excel at understanding and acting upon information. They can analyze intricate data sets, identify patterns, and formulate strategies to achieve specific goals. This ability stems from their deep integration with Retrieval-Augmented Generation (RAG) techniques.\n\n## The Power of RAG\n\nRAG empowers agents to not only access and process information but also to generate coherent and contextually relevant responses. This is crucial for tasks that require nuanced understanding and the ability to synthesize information from diverse sources. The agent retrieves relevant information, then uses that information to \"augment\" its generation process.\n\nLlamaIndex is often preferred over frameworks like LangChain or CrewAI due to its strong focus on data. It's designed from the ground up to handle the complexities of working with structured and unstructured data, ensuring that agents have the best possible foundation for reasoning and decision-making.\n\n## Agent Capabilities in Action\n\nImagine an agent tasked with analyzing a company's internal knowledge base to answer employee questions about HR policies. The agent can retrieve the relevant policy documents, understand the context of the question, and generate a clear and concise answer, saving HR staff valuable time. This is just one example of the many ways LlamaIndex agents can be applied.\n\nThese agents can be tailored to a wide range of applications, from customer service automation to financial analysis and scientific research. The key is to provide them with access to the right data and define clear objectives.\n\nLlamaIndex provides the tools and infrastructure needed to build and deploy these powerful agents, allowing organizations to unlock the full potential of their data. By automating complex tasks and providing intelligent insights, LlamaIndex agents are transforming the way we work.\n\nThe ability to reason and act on information is a critical step towards truly intelligent automation. LlamaIndex is leading the charge in this exciting field.\n```\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"from gtts import gTTS\n\ndef blog_to_audio(markdown_text, filename=\"blog_audio.mp3\"):\n    tts = gTTS(markdown_text)\n    tts.save(filename)\n    return filename\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T05:31:48.201741Z","iopub.execute_input":"2025-12-05T05:31:48.202128Z","iopub.status.idle":"2025-12-05T05:31:48.224373Z","shell.execute_reply.started":"2025-12-05T05:31:48.202099Z","shell.execute_reply":"2025-12-05T05:31:48.223395Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"audio_file = blog_to_audio(result[\"blog_markdown\"])\naudio_file\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T05:31:59.946217Z","iopub.execute_input":"2025-12-05T05:31:59.947235Z","iopub.status.idle":"2025-12-05T05:32:05.657224Z","shell.execute_reply.started":"2025-12-05T05:31:59.947198Z","shell.execute_reply":"2025-12-05T05:32:05.656147Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"'blog_audio.mp3'"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"out = graph.invoke({\"text\": input_text})\nmd = out[\"blog_markdown\"]\n\nlinkedin_post = render_for_platform(md, \"linkedin\")[\"content\"]\nmedium_post = render_for_platform(md, \"medium\")[\"content\"]\nsubstack_post = render_for_platform(md, \"substack\")[\"content\"]\ninstagram_post = render_for_platform(md, \"instagram\")[\"content\"]\n\n# print results\nprint(\"---- RAW MARKDOWN ----\")\nprint(md)\nprint(\"\\n\\n---- LINKEDIN VERSION ----\")\nprint(linkedin_post)\nprint(\"\\n\\n---- MEDIUM VERSION ----\")\nprint(medium_post)\nprint(\"\\n\\n---- SUBSTACK VERSION ----\")\nprint(substack_post)\nprint(\"\\n\\n---- INSTAGRAM VERSION ----\")\nprint(instagram_post)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T05:34:49.697745Z","iopub.execute_input":"2025-12-05T05:34:49.698179Z","iopub.status.idle":"2025-12-05T05:34:56.592072Z","shell.execute_reply.started":"2025-12-05T05:34:49.698153Z","shell.execute_reply":"2025-12-05T05:34:56.590564Z"}},"outputs":[{"name":"stdout","text":"---- RAW MARKDOWN ----\n```markdown\n# Beyond Chatbots: LlamaIndex Agents and the Future of Intelligent AI\n\nWe're rapidly moving beyond the era of simple chatbots. The future of AI lies in intelligent agents capable of reasoning, decision-making, and automating complex tasks. LlamaIndex is emerging as a powerful framework for building these advanced AI agents, particularly when dealing with private or domain-specific knowledge.\n\nLlamaIndex agents are essentially AI-powered engines that can analyze information, strategize, and execute actions to achieve specific goals. They leverage large language models (LLMs) but go far beyond basic question answering. Think of them as digital assistants capable of handling multifaceted projects, from research and analysis to content creation and data management.\n\n## LlamaIndex's Data-Centric Advantage\n\nWhat sets LlamaIndex apart from other agent-building frameworks? Its core strength lies in its data-centric approach. LlamaIndex excels at integrating and managing diverse data sources, allowing agents to access and leverage information effectively. This makes it particularly well-suited for applications where access to private or specialized knowledge is crucial.\n\nCompared to frameworks like LangChain or CrewAI, LlamaIndex is often lauded for its robust Retrieval-Augmented Generation (RAG) capabilities. RAG enables agents to ground their responses in real-world data, ensuring accuracy and relevance. This is critical for building trustworthy and reliable AI systems.\n\n## Applications and Future Potential\n\nThe potential applications of LlamaIndex agents are vast. Imagine agents that can automatically generate reports from financial data, conduct in-depth market research, or even manage complex supply chains. The ability to automate tasks that previously required significant human effort opens up exciting possibilities across various industries.\n\nAs LLMs continue to evolve and LlamaIndex's capabilities expand, we can expect to see even more sophisticated and versatile AI agents emerge. These agents will play an increasingly important role in shaping the future of work and transforming the way we interact with technology.\n\nThe possibilities are truly limitless.\nLlamaIndex agents are the future of intelligent automation.\n```\n\n\n---- LINKEDIN VERSION ----\n```markdown\n# Beyond Chatbots: LlamaIndex Agents and the Future of Intelligent AI\n\nWe're rapidly moving beyond the era of simple chatbots. The future of AI lies in intelligent agents capable of reasoning, decision-making, and automating complex tasks. LlamaIndex is emerging as a powerful framework for building these advanced AI agents, particularly when dealing with private or domain-specific knowledge.\n\nLlamaIndex agents are essentially AI-powered engines that can analyze information, strategize, and execute actions to achieve specific goals. They leverage large language models (LLMs) but go far beyond basic question answering. Think of them as digital assistants capable of handling multifaceted projects, from research and analysis to content creation and data management.\n\n#### LlamaIndex's Data-Centric Advantage\n\nWhat sets LlamaIndex apart from other agent-building frameworks? Its core strength lies in its data-centric approach. LlamaIndex excels at integrating and managing diverse data sources, allowing agents to access and leverage information effectively. This makes it particularly well-suited for applications where access to private or specialized knowledge is crucial.\n\nCompared to frameworks like LangChain or CrewAI, LlamaIndex is often lauded for its robust Retrieval-Augmented Generation (RAG) capabilities. RAG enables agents to ground their responses in real-world data, ensuring accuracy and relevance. This is critical for building trustworthy and reliable AI systems.\n\n#### Applications and Future Potential\n\nThe potential applications of LlamaIndex agents are vast. Imagine agents that can automatically generate reports from financial data, conduct in-depth market research, or even manage complex supply chains. The ability to automate tasks that previously required significant human effort opens up exciting possibilities across various industries.\n\nAs LLMs continue to evolve and LlamaIndex's capabilities expand, we can expect to see even more sophisticated and versatile AI agents emerge. These agents will play an increasingly important role in shaping the future of work and transforming the way we interact with technology.\n\nThe possibilities are truly limitless.\nLlamaIndex agents are the future of intelligent automation.\n```\n\n\n---- MEDIUM VERSION ----\n```markdown\n# Beyond Chatbots: LlamaIndex Agents and the Future of Intelligent AI\n\nWe're rapidly moving beyond the era of simple chatbots. The future of AI lies in intelligent agents capable of reasoning, decision-making, and automating complex tasks. LlamaIndex is emerging as a powerful framework for building these advanced AI agents, particularly when dealing with private or domain-specific knowledge.\n\nLlamaIndex agents are essentially AI-powered engines that can analyze information, strategize, and execute actions to achieve specific goals. They leverage large language models (LLMs) but go far beyond basic question answering. Think of them as digital assistants capable of handling multifaceted projects, from research and analysis to content creation and data management.\n\n## LlamaIndex's Data-Centric Advantage\n\nWhat sets LlamaIndex apart from other agent-building frameworks? Its core strength lies in its data-centric approach. LlamaIndex excels at integrating and managing diverse data sources, allowing agents to access and leverage information effectively. This makes it particularly well-suited for applications where access to private or specialized knowledge is crucial.\n\nCompared to frameworks like LangChain or CrewAI, LlamaIndex is often lauded for its robust Retrieval-Augmented Generation (RAG) capabilities. RAG enables agents to ground their responses in real-world data, ensuring accuracy and relevance. This is critical for building trustworthy and reliable AI systems.\n\n## Applications and Future Potential\n\nThe potential applications of LlamaIndex agents are vast. Imagine agents that can automatically generate reports from financial data, conduct in-depth market research, or even manage complex supply chains. The ability to automate tasks that previously required significant human effort opens up exciting possibilities across various industries.\n\nAs LLMs continue to evolve and LlamaIndex's capabilities expand, we can expect to see even more sophisticated and versatile AI agents emerge. These agents will play an increasingly important role in shaping the future of work and transforming the way we interact with technology.\n\nThe possibilities are truly limitless.\nLlamaIndex agents are the future of intelligent automation.\n```\n\n\n---- SUBSTACK VERSION ----\n```markdown\n# Beyond Chatbots: LlamaIndex Agents and the Future of Intelligent AI\n\nWe're rapidly moving beyond the era of simple chatbots. The future of AI lies in intelligent agents capable of reasoning, decision-making, and automating complex tasks. LlamaIndex is emerging as a powerful framework for building these advanced AI agents, particularly when dealing with private or domain-specific knowledge.\n\nLlamaIndex agents are essentially AI-powered engines that can analyze information, strategize, and execute actions to achieve specific goals. They leverage large language models (LLMs) but go far beyond basic question answering. Think of them as digital assistants capable of handling multifaceted projects, from research and analysis to content creation and data management.\n\n## LlamaIndex's Data-Centric Advantage\n\nWhat sets LlamaIndex apart from other agent-building frameworks? Its core strength lies in its data-centric approach. LlamaIndex excels at integrating and managing diverse data sources, allowing agents to access and leverage information effectively. This makes it particularly well-suited for applications where access to private or specialized knowledge is crucial.\n\nCompared to frameworks like LangChain or CrewAI, LlamaIndex is often lauded for its robust Retrieval-Augmented Generation (RAG) capabilities. RAG enables agents to ground their responses in real-world data, ensuring accuracy and relevance. This is critical for building trustworthy and reliable AI systems.\n\n## Applications and Future Potential\n\nThe potential applications of LlamaIndex agents are vast. Imagine agents that can automatically generate reports from financial data, conduct in-depth market research, or even manage complex supply chains. The ability to automate tasks that previously required significant human effort opens up exciting possibilities across various industries.\n\nAs LLMs continue to evolve and LlamaIndex's capabilities expand, we can expect to see even more sophisticated and versatile AI agents emerge. These agents will play an increasingly important role in shaping the future of work and transforming the way we interact with technology.\n\nThe possibilities are truly limitless.\nLlamaIndex agents are the future of intelligent automation.\n```\n\n---\n*Written via AI Blog Generator*\n\n\n---- INSTAGRAM VERSION ----\n```markdown\n\n# Beyond Chatbots: LlamaIndex Agents and the Future of Intelligent AI\n\nWe're rapidly moving beyond the era of simple chatbots. The future of AI lies in intelligent agents capable of reasoning, decision-making, and automating complex tasks. LlamaIndex is emerging as a powerful framework for building these advanced AI agents, particularly when dealing with private or domain-specific knowledge.\n\nLlamaIndex agents are essentially AI-powered engines that can analyze information, strategize, and execute actions to achieve specific goals. They leverage large language models (LLMs) but go far beyond basic question answering. Think of them as digital assistants capable of handling multifaceted projects, from research and analysis to content creation and data management.\n\n## LlamaIndex's Data-Centric Advantage\n\nWhat sets LlamaIndex apart from other agent-building frameworks? Its core strength lies in its data-centric approach. LlamaIndex excels at integrating and managing diverse data sources, allowing agents to access and leverage information effectively. This makes it particularly well-suited for applications where access to private or specialized knowledge is crucial.\n\nCompared to frameworks like LangChain or CrewAI, LlamaIndex is often lauded for its robust Retrieval-Augmented Generation (RAG) capabilities. RAG enables agents to ground their responses in real-world data, ensuring accuracy and relevance. This is critical for building trustworthy and reliable AI systems.\n\n## Applications and Future Potential\n\nThe potential applications of LlamaIndex agents are vast. Imagine agents that can automatically generate reports from financial data, conduct in-depth market research, or even manage complex supply chains. The ability to automate tasks that previously required significant human effort opens up exciting possibilities across various industries.\n\nAs LLMs continue to evolve and LlamaIndex's capabilities expand, we can expect to see even more sophisticated and versatile AI agents emerge. These agents will play an increasingly important role in shaping the future of work and transforming the way we interact with technology.\n\nThe possibilities are truly limitless.\n\nLlamaIndex agents are the future of intelligent automation.\n\n```\n","output_type":"stream"}],"execution_count":25}]}